{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Multi-Objective NAS with Ax\n",
        "\n",
        "**Authors:** [David Eriksson](https://github.com/dme65)_,\n",
        "[Max Balandat](https://github.com/Balandat)_,\n",
        "and the Adaptive Experimentation team at Meta.\n",
        "\n",
        "In this tutorial, we show how to use [Ax](https://ax.dev/)_ to run\n",
        "multi-objective neural architecture search (NAS) for a simple neural\n",
        "network model on the popular MNIST dataset. While the underlying\n",
        "methodology would typically be used for more complicated models and\n",
        "larger datasets, we opt for a tutorial that is easily runnable\n",
        "end-to-end on a laptop in less than 20 minutes.\n",
        "\n",
        "In many NAS applications, there is a natural tradeoff between multiple\n",
        "objectives of interest. For instance, when deploying models on-device\n",
        "we may want to maximize model performance (for example, accuracy), while\n",
        "simultaneously minimizing competing metrics like power consumption,\n",
        "inference latency, or model size in order to satisfy deployment\n",
        "constraints. Often, we may be able to reduce computational requirements\n",
        "or latency of predictions substantially by accepting minimally lower\n",
        "model performance. Principled methods for exploring such tradeoffs\n",
        "efficiently are key enablers of scalable and sustainable AI, and have\n",
        "many successful applications at Meta - see for instance our\n",
        "[case study](https://research.facebook.com/blog/2021/07/optimizing-model-accuracy-and-latency-using-bayesian-multi-objective-neural-architecture-search/)_\n",
        "on a Natural Language Understanding model.\n",
        "\n",
        "In our example here, we will tune the widths of two hidden layers,\n",
        "the learning rate, the dropout probability, the batch size, and the\n",
        "number of training epochs. The goal is to trade off performance\n",
        "(accuracy on the validation set) and model size (the number of\n",
        "model parameters).\n",
        "\n",
        "This tutorial makes use of the following PyTorch libraries:\n",
        "\n",
        "- [PyTorch Lightning](https://github.com/PyTorchLightning/pytorch-lightning)_ (specifying the model and training loop)\n",
        "- [TorchX](https://github.com/pytorch/torchx)_ (for running training jobs remotely / asynchronously)\n",
        "- [BoTorch](https://github.com/pytorch/botorch)_ (the Bayesian Optimization library powering Ax's algorithms)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the TorchX App\n",
        "\n",
        "Our goal is to optimize the PyTorch Lightning training job defined in\n",
        "[mnist_train_nas.py](https://github.com/pytorch/tutorials/tree/master/intermediate_source/mnist_train_nas.py)_.\n",
        "To do this using TorchX, we write a helper function that takes in\n",
        "the values of the architcture and hyperparameters of the training\n",
        "job and creates a [TorchX AppDef](https://pytorch.org/torchx/latest/basics.html)_\n",
        "with the appropriate settings.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import torchx\n",
        "\n",
        "from torchx import specs\n",
        "from torchx.components import utils\n",
        "\n",
        "\n",
        "def trainer(\n",
        "    log_path: str,\n",
        "    hidden_size_1: int,\n",
        "    hidden_size_2: int,\n",
        "    learning_rate: float,\n",
        "    epochs: int,\n",
        "    dropout: float,\n",
        "    batch_size: int,\n",
        "    trial_idx: int = -1,\n",
        ") -> specs.AppDef:\n",
        "\n",
        "    # define the log path so we can pass it to the TorchX AppDef\n",
        "    if trial_idx >= 0:\n",
        "        log_path = Path(log_path).joinpath(str(trial_idx)).absolute().as_posix()\n",
        "\n",
        "    return utils.python(\n",
        "        # command line args to the training script\n",
        "        \"--log_path\",\n",
        "        log_path,\n",
        "        \"--hidden_size_1\",\n",
        "        str(hidden_size_1),\n",
        "        \"--hidden_size_2\",\n",
        "        str(hidden_size_2),\n",
        "        \"--learning_rate\",\n",
        "        str(learning_rate),\n",
        "        \"--epochs\",\n",
        "        str(epochs),\n",
        "        \"--dropout\",\n",
        "        str(dropout),\n",
        "        \"--batch_size\",\n",
        "        str(batch_size),\n",
        "        # other config options\n",
        "        name=\"trainer\",\n",
        "        script=\"mnist_train_nas.py\",\n",
        "        image=torchx.version.TORCHX_IMAGE,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the Runner\n",
        "\n",
        "Axâ€™s [Runner](https://ax.dev/api/core.html#ax.core.runner.Runner)_\n",
        "abstraction allows writing interfaces to various backends.\n",
        "Ax already comes with Runner for TorchX, and so we just need to\n",
        "configure it. For the purpose of this tutorial we run jobs locally\n",
        "in a fully asynchronous fashion.\n",
        "\n",
        "In order to launch them on a cluster, you can instead specify a\n",
        "different TorchX scheduler and adjust the configuration appropriately.\n",
        "For example, if you have a Kubernetes cluster, you just need to change the\n",
        "scheduler from ``local_cwd`` to ``kubernetes``).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/pc2005/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import tempfile\n",
        "from ax.runners.torchx import TorchXRunner\n",
        "\n",
        "# Make a temporary dir to log our results into\n",
        "log_dir = tempfile.mkdtemp()\n",
        "\n",
        "ax_runner = TorchXRunner(\n",
        "    tracker_base=\"/tmp/\",\n",
        "    component=trainer,\n",
        "    # NOTE: To launch this job on a cluster instead of locally you can\n",
        "    # specify a different scheduler and adjust args appropriately.\n",
        "    scheduler=\"local_cwd\",\n",
        "    component_const_params={\"log_path\": log_dir},\n",
        "    cfg={},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the SearchSpace\n",
        "\n",
        "First, we define our search space. Ax supports both range parameters\n",
        "of type integer and float as well as choice parameters which can have\n",
        "non-numerical types such as strings.\n",
        "We will tune the hidden sizes, learning rate, dropout, and number of\n",
        "epochs as range parameters and tune the batch size as an ordered choice\n",
        "parameter to enforce it to be a power of 2.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ax.core import (\n",
        "    ChoiceParameter,\n",
        "    ParameterType,\n",
        "    RangeParameter,\n",
        "    SearchSpace,\n",
        ")\n",
        "\n",
        "parameters = [\n",
        "    # NOTE: In a real-world setting, hidden_size_1 and hidden_size_2\n",
        "    # should probably be powers of 2, but in our simple example this\n",
        "    # would mean that num_params can't take on that many values, which\n",
        "    # in turn makes the Pareto frontier look pretty weird.\n",
        "    RangeParameter(\n",
        "        name=\"hidden_size_1\",\n",
        "        lower=16,\n",
        "        upper=128,\n",
        "        parameter_type=ParameterType.INT,\n",
        "        log_scale=True,\n",
        "    ),\n",
        "    RangeParameter(\n",
        "        name=\"hidden_size_2\",\n",
        "        lower=16,\n",
        "        upper=128,\n",
        "        parameter_type=ParameterType.INT,\n",
        "        log_scale=True,\n",
        "    ),\n",
        "    RangeParameter(\n",
        "        name=\"learning_rate\",\n",
        "        lower=1e-4,\n",
        "        upper=1e-2,\n",
        "        parameter_type=ParameterType.FLOAT,\n",
        "        log_scale=True,\n",
        "    ),\n",
        "    RangeParameter(\n",
        "        name=\"epochs\",\n",
        "        lower=1,\n",
        "        upper=4,\n",
        "        parameter_type=ParameterType.INT,\n",
        "    ),\n",
        "    RangeParameter(\n",
        "        name=\"dropout\",\n",
        "        lower=0.0,\n",
        "        upper=0.5,\n",
        "        parameter_type=ParameterType.FLOAT,\n",
        "    ),\n",
        "    ChoiceParameter(  # NOTE: ChoiceParameters don't require log-scale\n",
        "        name=\"batch_size\",\n",
        "        values=[32, 64, 128, 256],\n",
        "        parameter_type=ParameterType.INT,\n",
        "        is_ordered=True,\n",
        "        sort_values=True,\n",
        "    ),\n",
        "]\n",
        "\n",
        "search_space = SearchSpace(\n",
        "    parameters=parameters,\n",
        "    # NOTE: In practice, it may make sense to add a constraint\n",
        "    # hidden_size_2 <= hidden_size_1\n",
        "    parameter_constraints=[],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up Metrics\n",
        "\n",
        "Ax has the concept of a [Metric](https://ax.dev/api/core.html#metric)_\n",
        "that defines properties of outcomes and how observations are obtained\n",
        "for these outcomes. This allows e.g. encodig how data is fetched from\n",
        "some distributed execution backend and post-processed before being\n",
        "passed as input to Ax.\n",
        "\n",
        "In this tutorial we will use\n",
        "[multi-objective optimization](https://ax.dev/tutorials/multiobjective_optimization.html)_\n",
        "with the goal of maximizing the validation accuracy and minimizing\n",
        "the number of model parameters. The latter represents a simple proxy\n",
        "of model latency, which is hard to estimate accurately for small ML\n",
        "models (in an actual application we would benchmark the latency while\n",
        "running the model on-device).\n",
        "\n",
        "In our example TorchX will run the training jobs in a fully asynchronous\n",
        "fashion locally and write the results to the ``log_dir`` based on the trial\n",
        "index (see the ``trainer()`` function above). We will define a metric\n",
        "class that is aware of that logging directory. By subclassing\n",
        "[TensorboardCurveMetric](https://ax.dev/api/metrics.html?highlight=tensorboardcurvemetric#ax.metrics.tensorboard.TensorboardCurveMetric)_\n",
        "we get the logic to read and parse the Tensorboard logs for free.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ax.metrics.tensorboard import TensorboardCurveMetric\n",
        "\n",
        "\n",
        "class MyTensorboardMetric(TensorboardCurveMetric):\n",
        "\n",
        "    # NOTE: We need to tell the new Tensorboard metric how to get the id /\n",
        "    # file handle for the tensorboard logs from a trial. In this case\n",
        "    # our convention is to just save a separate file per trial in\n",
        "    # the pre-specified log dir.\n",
        "    @classmethod\n",
        "    def get_ids_from_trials(cls, trials):\n",
        "        return {\n",
        "            trial.index: Path(log_dir).joinpath(str(trial.index)).as_posix()\n",
        "            for trial in trials\n",
        "        }\n",
        "\n",
        "    # This indicates whether the metric is queryable while the trial is\n",
        "    # still running. We don't use this in the current tutorial, but Ax\n",
        "    # utilizes this to implement trial-level early-stopping functionality.\n",
        "    @classmethod\n",
        "    def is_available_while_running(cls):\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can instatiate the metrics for accuracy and the number of\n",
        "model parameters. Here `curve_name` is the name of the metric in the\n",
        "Tensorboard logs, while `name` is the metric name used internally\n",
        "by Ax. We also specify `lower_is_better` to indicate the favorable\n",
        "direction of the two metrics.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "val_acc = MyTensorboardMetric(\n",
        "    name=\"val_acc\",\n",
        "    curve_name=\"val_acc\",\n",
        "    lower_is_better=False,\n",
        ")\n",
        "model_num_params = MyTensorboardMetric(\n",
        "    name=\"num_params\",\n",
        "    curve_name=\"num_params\",\n",
        "    lower_is_better=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting up the OptimizationConfig\n",
        "\n",
        "The way to tell Ax what it should optimize is by means of an\n",
        "[OptimizationConfig](https://ax.dev/api/core.html#module-ax.core.optimization_config)_.\n",
        "Here we use a ``MultiObjectiveOptimizationConfig`` as we will\n",
        "be performing multi-objective optimization.\n",
        "\n",
        "Additionally, Ax supports placing constraints on the different\n",
        "metrics by specifying objective thresholds, which bound the region\n",
        "of interest in the outcome space that we want to explore. For this\n",
        "example, we will constrain the validation accuracy to be at least\n",
        "0.94 (94%) and the number of model parameters to be at most 80,000.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ax.core import MultiObjective, Objective, ObjectiveThreshold\n",
        "from ax.core.optimization_config import MultiObjectiveOptimizationConfig\n",
        "\n",
        "\n",
        "opt_config = MultiObjectiveOptimizationConfig(\n",
        "    objective=MultiObjective(\n",
        "        objectives=[\n",
        "            Objective(metric=val_acc, minimize=False),\n",
        "            Objective(metric=model_num_params, minimize=True),\n",
        "        ],\n",
        "    ),\n",
        "    objective_thresholds=[\n",
        "        ObjectiveThreshold(metric=val_acc, bound=0.94, relative=False),\n",
        "        ObjectiveThreshold(metric=model_num_params, bound=80_000, relative=False),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating the Ax Experiment\n",
        "\n",
        "In Ax, the [Experiment](https://ax.dev/api/core.html#ax.core.experiment.Experiment)_\n",
        "object is the object that stores all the information about the problem\n",
        "setup.\n",
        "\n",
        ".. tip:\n",
        "  ``Experiment`` objects can be serialized to JSON or stored to a\n",
        "  database backend such as MySQL in order to persist and be available\n",
        "  to load on different machines. See the the [Ax Docs](https://ax.dev/docs/storage.html)_\n",
        "  on the storage functionality for details.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ax.core import Experiment\n",
        "\n",
        "experiment = Experiment(\n",
        "    name=\"torchx_mnist\",\n",
        "    search_space=search_space,\n",
        "    optimization_config=opt_config,\n",
        "    runner=ax_runner,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choosing the GenerationStrategy\n",
        "\n",
        "A [GenerationStrategy](https://ax.dev/api/modelbridge.html#ax.modelbridge.generation_strategy.GenerationStrategy)_\n",
        "is the abstract representation of how we would like to perform the\n",
        "optimization. While this can be customized (if youâ€™d like to do so, see\n",
        "[this tutorial](https://ax.dev/tutorials/generation_strategy.html)_),\n",
        "in most cases Ax can automatically determine an appropriate strategy\n",
        "based on the search space, optimization config, and the total number\n",
        "of trials we want to run.\n",
        "\n",
        "Typically, Ax chooses to evaluate a number of random configurations\n",
        "before starting a model-based Bayesian Optimization strategy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO 11-24 21:21:16] ax.modelbridge.dispatch_utils: Using Bayesian optimization since there are more ordered parameters than there are categories for the unordered categorical parameters.\n",
            "[INFO 11-24 21:21:16] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+MOO', steps=[Sobol for 9 trials, MOO for subsequent trials]). Iterations after 9 will take longer to generate due to  model-fitting.\n"
          ]
        }
      ],
      "source": [
        "total_trials = 48  # total evaluation budget\n",
        "\n",
        "from ax.modelbridge.dispatch_utils import choose_generation_strategy\n",
        "\n",
        "gs = choose_generation_strategy(\n",
        "    search_space=experiment.search_space,\n",
        "    optimization_config=experiment.optimization_config,\n",
        "    num_trials=total_trials,\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuring the Scheduler\n",
        "\n",
        "The `Scheduler` (TODO: link) acts as the loop control for the optimization.\n",
        "It communicates with the backend to launch trials, check their status,\n",
        "and retrieve results. In the case of this tutorial, it is simply reading\n",
        "and parsing the locally saved logs. In a remote execution setting,\n",
        "it would call APIs. The following illustration from the Ax\n",
        "[Scheduler tutorial](https://ax.dev/tutorials/scheduler.html)_\n",
        "summarizes how the Scheduler interacts with external systems used to run\n",
        "trial evaluations:\n",
        "\n",
        "<img src=\"file://../../_static/img/ax_scheduler_illustration.png\">\n",
        "\n",
        "\n",
        "The ``Scheduler`` requires the ``Experiment`` and the ``GenerationStrategy``.\n",
        "A set of options can be passed in via ``SchedulerOptions``. Here, we\n",
        "configure the number of total evaluations as well as ``max_pending_trials``,\n",
        "the maximum number of trials that should run concurrently. In our\n",
        "local setting, this is the number of training jobs running as individual\n",
        "processes, while in a remote execution setting, this would be the number\n",
        "of machines you want to use in parallel.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO 11-24 21:21:26] Scheduler: `Scheduler` requires experiment to have immutable search space and optimization config. Setting property immutable_search_space_and_opt_config to `True` on experiment.\n"
          ]
        }
      ],
      "source": [
        "from ax.service.scheduler import Scheduler, SchedulerOptions\n",
        "\n",
        "scheduler = Scheduler(\n",
        "    experiment=experiment,\n",
        "    generation_strategy=gs,\n",
        "    options=SchedulerOptions(\n",
        "        total_trials=total_trials, max_pending_trials=4\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the optimization\n",
        "\n",
        "Now that everything is configured, we can let Ax run the optimization\n",
        "in a fully automated fashion. The Scheduler will periodially check\n",
        "the logs for the status of all currently running trials, and if a\n",
        "trial completes the scheduler will update its status on the\n",
        "experiment and fetch the observations needed for the Bayesian\n",
        "optimization algorithm.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/pc2005/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/core/observation.py:274: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
            "  for g, d in df.groupby(by=cols):\n",
            "[INFO 11-24 21:21:32] Scheduler: Running trials [0]...\n",
            "/Users/pc2005/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/core/observation.py:274: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
            "  for g, d in df.groupby(by=cols):\n",
            "[INFO 11-24 21:21:33] Scheduler: Running trials [1]...\n",
            "/Users/pc2005/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/core/observation.py:274: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
            "  for g, d in df.groupby(by=cols):\n",
            "[INFO 11-24 21:21:33] Scheduler: Running trials [2]...\n",
            "/Users/pc2005/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/core/observation.py:274: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
            "  for g, d in df.groupby(by=cols):\n",
            "[INFO 11-24 21:21:34] Scheduler: Running trials [3]...\n",
            "[INFO 11-24 21:21:35] Scheduler: Retrieved FAILED trials: 0 - 3.\n",
            "/Users/pc2005/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/core/observation.py:274: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
            "  for g, d in df.groupby(by=cols):\n",
            "[INFO 11-24 21:21:35] Scheduler: Running trials [4]...\n",
            "/Users/pc2005/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/core/observation.py:274: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
            "  for g, d in df.groupby(by=cols):\n",
            "[INFO 11-24 21:21:36] Scheduler: Running trials [5]...\n",
            "/Users/pc2005/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/core/observation.py:274: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
            "  for g, d in df.groupby(by=cols):\n",
            "[INFO 11-24 21:21:36] Scheduler: Running trials [6]...\n",
            "/Users/pc2005/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/core/observation.py:274: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
            "  for g, d in df.groupby(by=cols):\n",
            "[INFO 11-24 21:21:37] Scheduler: Running trials [7]...\n",
            "[INFO 11-24 21:21:39] Scheduler: Retrieved FAILED trials: 4 - 7.\n"
          ]
        },
        {
          "ename": "FailureRateExceededError",
          "evalue": "Failure rate exceeds the tolerated trial failure rate of 0.5 (at least 8 out of first 8 trials failed). Checks are triggered both at the end of a optimization and if at least 5 trials have failed.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailureRateExceededError\u001b[0m                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scheduler\u001b[39m.\u001b[39;49mrun_all_trials()\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/service/scheduler.py:949\u001b[0m, in \u001b[0;36mScheduler.run_all_trials\u001b[0;34m(self, timeout_hours, idle_callback)\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mtotal_trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    943\u001b[0m     \u001b[39m# NOTE: Capping on number of trials will likely be needed as fallback\u001b[39;00m\n\u001b[1;32m    944\u001b[0m     \u001b[39m# for most stopping criteria, so we ensure `num_trials` is specified.\u001b[39;00m\n\u001b[1;32m    945\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    946\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease either specify `num_trials` in `SchedulerOptions` input \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    947\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto the `Scheduler` or use `run_n_trials` instead of `run_all_trials`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    948\u001b[0m     )\n\u001b[0;32m--> 949\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trials_and_yield_results(\n\u001b[1;32m    950\u001b[0m     max_trials\u001b[39m=\u001b[39mnot_none(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mtotal_trials),\n\u001b[1;32m    951\u001b[0m     timeout_hours\u001b[39m=\u001b[39mtimeout_hours,\n\u001b[1;32m    952\u001b[0m     idle_callback\u001b[39m=\u001b[39midle_callback,\n\u001b[1;32m    953\u001b[0m ):\n\u001b[1;32m    954\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    955\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msummarize_final_result()\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/service/scheduler.py:806\u001b[0m, in \u001b[0;36mScheduler.run_trials_and_yield_results\u001b[0;34m(self, max_trials, ignore_global_stopping_strategy, timeout_hours, idle_callback)\u001b[0m\n\u001b[1;32m    801\u001b[0m n_remaining_to_run \u001b[39m=\u001b[39m max_trials\n\u001b[1;32m    802\u001b[0m \u001b[39mwhile\u001b[39;00m (\n\u001b[1;32m    803\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshould_consider_optimization_complete()[\u001b[39m0\u001b[39m]\n\u001b[1;32m    804\u001b[0m     \u001b[39mand\u001b[39;00m n_remaining_to_run \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    805\u001b[0m ):\n\u001b[0;32m--> 806\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshould_abort_optimization():\n\u001b[1;32m    807\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_abort_optimization(num_preexisting_trials\u001b[39m=\u001b[39mn_existing)\n\u001b[1;32m    808\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/service/scheduler.py:672\u001b[0m, in \u001b[0;36mScheduler.should_abort_optimization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39m\"\"\"Checks whether this scheduler has reached some intertuption / abort\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[39mcriterion, such as an overall optimization timeout, tolerated failure rate, etc.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    670\u001b[0m \u001b[39m# if failure rate is exceeded, raise an exception.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \u001b[39m# this check should precede others to ensure it is not skipped.\u001b[39;00m\n\u001b[0;32m--> 672\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_if_failure_rate_exceeded()\n\u001b[1;32m    674\u001b[0m \u001b[39m# if optimization is timed out, return True, else return False\u001b[39;00m\n\u001b[1;32m    675\u001b[0m timed_out \u001b[39m=\u001b[39m (\n\u001b[1;32m    676\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_hours \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    677\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_latest_optimization_start_timestamp \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m not_none(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_hours) \u001b[39m*\u001b[39m \u001b[39m60\u001b[39m \u001b[39m*\u001b[39m \u001b[39m60\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m    681\u001b[0m )\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/service/scheduler.py:727\u001b[0m, in \u001b[0;36mScheduler.error_if_failure_rate_exceeded\u001b[0;34m(self, force_check)\u001b[0m\n\u001b[1;32m    722\u001b[0m failure_rate_exceeded \u001b[39m=\u001b[39m (\n\u001b[1;32m    723\u001b[0m     num_failed_in_scheduler \u001b[39m/\u001b[39m num_ran_in_scheduler\n\u001b[1;32m    724\u001b[0m ) \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mtolerated_trial_failure_rate\n\u001b[1;32m    726\u001b[0m \u001b[39mif\u001b[39;00m failure_rate_exceeded:\n\u001b[0;32m--> 727\u001b[0m     \u001b[39mraise\u001b[39;00m FailureRateExceededError(\n\u001b[1;32m    728\u001b[0m         FAILURE_EXCEEDED_MSG\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    729\u001b[0m             f_rate\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mtolerated_trial_failure_rate,\n\u001b[1;32m    730\u001b[0m             n_failed\u001b[39m=\u001b[39mnum_failed_in_scheduler,\n\u001b[1;32m    731\u001b[0m             n_ran\u001b[39m=\u001b[39mnum_ran_in_scheduler,\n\u001b[1;32m    732\u001b[0m             min_failed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mmin_failed_trials_for_failure_rate_check,\n\u001b[1;32m    733\u001b[0m         )\n\u001b[1;32m    734\u001b[0m     )\n",
            "\u001b[0;31mFailureRateExceededError\u001b[0m: Failure rate exceeds the tolerated trial failure rate of 0.5 (at least 8 out of first 8 trials failed). Checks are triggered both at the end of a optimization and if at least 5 trials have failed."
          ]
        }
      ],
      "source": [
        "scheduler.run_all_trials()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating the results\n",
        "\n",
        "We can now inspect the result of the optimization using helper\n",
        "functions and visualizations included with Ax.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we generate a dataframe with a summary of the results\n",
        "of the experiment. Each row in this dataframe corresponds to a\n",
        "trial (that is, a training job that was run), and contains information\n",
        "on the status of the trial, the parameter configuration that was\n",
        "evaluated, and the metric values that were observed. This provides\n",
        "an easy way to sanity check the optimization.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO 11-24 21:22:37] ax.service.utils.report_utils: No results present for the specified metrics `[MyTensorboardMetric('val_acc'), MyTensorboardMetric('num_params')]`. Returning arm parameters and metadata only.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>arm_name</th>\n",
              "      <th>trial_index</th>\n",
              "      <th>hidden_size_1</th>\n",
              "      <th>hidden_size_2</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>epochs</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>trial_status</th>\n",
              "      <th>generation_method</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0_0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>35</td>\n",
              "      <td>0.003455</td>\n",
              "      <td>2</td>\n",
              "      <td>0.330290</td>\n",
              "      <td>256</td>\n",
              "      <td>FAILED</td>\n",
              "      <td>Sobol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1_0</td>\n",
              "      <td>1</td>\n",
              "      <td>67</td>\n",
              "      <td>22</td>\n",
              "      <td>0.000406</td>\n",
              "      <td>4</td>\n",
              "      <td>0.337095</td>\n",
              "      <td>128</td>\n",
              "      <td>FAILED</td>\n",
              "      <td>Sobol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2_0</td>\n",
              "      <td>2</td>\n",
              "      <td>19</td>\n",
              "      <td>112</td>\n",
              "      <td>0.000930</td>\n",
              "      <td>1</td>\n",
              "      <td>0.028110</td>\n",
              "      <td>256</td>\n",
              "      <td>FAILED</td>\n",
              "      <td>Sobol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3_0</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>49</td>\n",
              "      <td>0.000663</td>\n",
              "      <td>1</td>\n",
              "      <td>0.297129</td>\n",
              "      <td>64</td>\n",
              "      <td>FAILED</td>\n",
              "      <td>Sobol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4_0</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>29</td>\n",
              "      <td>0.002896</td>\n",
              "      <td>4</td>\n",
              "      <td>0.361443</td>\n",
              "      <td>128</td>\n",
              "      <td>FAILED</td>\n",
              "      <td>Sobol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5_0</td>\n",
              "      <td>5</td>\n",
              "      <td>89</td>\n",
              "      <td>41</td>\n",
              "      <td>0.002323</td>\n",
              "      <td>3</td>\n",
              "      <td>0.194042</td>\n",
              "      <td>128</td>\n",
              "      <td>FAILED</td>\n",
              "      <td>Sobol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6_0</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>95</td>\n",
              "      <td>0.004708</td>\n",
              "      <td>3</td>\n",
              "      <td>0.368038</td>\n",
              "      <td>32</td>\n",
              "      <td>FAILED</td>\n",
              "      <td>Sobol</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7_0</td>\n",
              "      <td>7</td>\n",
              "      <td>33</td>\n",
              "      <td>17</td>\n",
              "      <td>0.000201</td>\n",
              "      <td>4</td>\n",
              "      <td>0.170623</td>\n",
              "      <td>256</td>\n",
              "      <td>FAILED</td>\n",
              "      <td>Sobol</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  arm_name  trial_index  hidden_size_1  hidden_size_2  learning_rate  epochs  \\\n",
              "0      0_0            0             48             35       0.003455       2   \n",
              "1      1_0            1             67             22       0.000406       4   \n",
              "2      2_0            2             19            112       0.000930       1   \n",
              "3      3_0            3             17             49       0.000663       1   \n",
              "4      4_0            4             23             29       0.002896       4   \n",
              "5      5_0            5             89             41       0.002323       3   \n",
              "6      6_0            6             16             95       0.004708       3   \n",
              "7      7_0            7             33             17       0.000201       4   \n",
              "\n",
              "    dropout  batch_size trial_status generation_method  \n",
              "0  0.330290         256       FAILED             Sobol  \n",
              "1  0.337095         128       FAILED             Sobol  \n",
              "2  0.028110         256       FAILED             Sobol  \n",
              "3  0.297129          64       FAILED             Sobol  \n",
              "4  0.361443         128       FAILED             Sobol  \n",
              "5  0.194042         128       FAILED             Sobol  \n",
              "6  0.368038          32       FAILED             Sobol  \n",
              "7  0.170623         256       FAILED             Sobol  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ax.service.utils.report_utils import exp_to_df\n",
        "\n",
        "df = exp_to_df(experiment)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also visualize the Pareto frontier of tradeoffs between the\n",
        "validation accuracy and the number of model parameters.\n",
        "\n",
        ".. tip::\n",
        "  Ax uses Plotly to produce interactive plots, which allow you to\n",
        "  do things like zoom, crop, or hover in order to view details\n",
        "  of components of the plot. Try it out, and take a look at the\n",
        "  [visualization tutorial](https://ax.dev/tutorials/visualizations.html)_\n",
        "  if you'd like to learn more).\n",
        "\n",
        "The final optimization results are shown in the figure below where\n",
        "the color corresponds to the iteration number for each trial.\n",
        "We see that our method was able to successfully explore the\n",
        "trade-offs and found both large models with high validation\n",
        "accuracy as well as small models with comparatively lower\n",
        "validation accuracy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO 11-24 21:22:41] ax.service.utils.report_utils: No results present for the specified metrics `[MyTensorboardMetric('val_acc'), MyTensorboardMetric('num_params')]`. Returning arm parameters and metadata only.\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "\"None of [Index(['val_acc', 'num_params'], dtype='object')] are in the [columns]\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39max\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mservice\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m _pareto_frontier_scatter_2d_plotly\n\u001b[0;32m----> 3\u001b[0m _pareto_frontier_scatter_2d_plotly(experiment)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/ax/service/utils/report_utils.py:676\u001b[0m, in \u001b[0;36m_pareto_frontier_scatter_2d_plotly\u001b[0;34m(experiment, metric_names, reference_point, minimize)\u001b[0m\n\u001b[1;32m    668\u001b[0m metric_names, reference_point, minimize \u001b[39m=\u001b[39m _pareto_frontier_plot_input_processing(\n\u001b[1;32m    669\u001b[0m     experiment\u001b[39m=\u001b[39mexperiment,\n\u001b[1;32m    670\u001b[0m     metric_names\u001b[39m=\u001b[39mmetric_names,\n\u001b[1;32m    671\u001b[0m     reference_point\u001b[39m=\u001b[39mreference_point,\n\u001b[1;32m    672\u001b[0m     minimize\u001b[39m=\u001b[39mminimize,\n\u001b[1;32m    673\u001b[0m )\n\u001b[1;32m    675\u001b[0m df \u001b[39m=\u001b[39m exp_to_df(experiment)\n\u001b[0;32m--> 676\u001b[0m Y \u001b[39m=\u001b[39m df[\u001b[39mlist\u001b[39;49m(metric_names)]\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m    677\u001b[0m Y_pareto \u001b[39m=\u001b[39m (\n\u001b[1;32m    678\u001b[0m     _extract_observed_pareto_2d(\n\u001b[1;32m    679\u001b[0m         Y\u001b[39m=\u001b[39mY, reference_point\u001b[39m=\u001b[39mreference_point, minimize\u001b[39m=\u001b[39mminimize\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    683\u001b[0m )\n\u001b[1;32m    685\u001b[0m hovertext \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mArm name: \u001b[39m\u001b[39m{\u001b[39;00marm_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m arm_name \u001b[39min\u001b[39;00m df[\u001b[39m\"\u001b[39m\u001b[39marm_name\u001b[39m\u001b[39m\"\u001b[39m]]\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/pandas/core/frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3810\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3811\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3813\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/pandas/core/indexes/base.py:6113\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6110\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6111\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6113\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6115\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6117\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/exp_pt/lib/python3.9/site-packages/pandas/core/indexes/base.py:6173\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6171\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6172\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 6173\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6175\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   6176\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['val_acc', 'num_params'], dtype='object')] are in the [columns]\""
          ]
        }
      ],
      "source": [
        "from ax.service.utils.report_utils import _pareto_frontier_scatter_2d_plotly\n",
        "\n",
        "_pareto_frontier_scatter_2d_plotly(experiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To better understand what our surrogate models have learned about\n",
        "the black box objectives, we can take a look at the leave-one-out\n",
        "cross validation results. Since our models are Gaussian Processes,\n",
        "they not only provide point predictions but also uncertainty estimates\n",
        "about these predictions. A good model means that the predicted means\n",
        "(the points in the figure) are close to the 45 degree line and that the\n",
        "confidence intervals cover the 45 degree line with the expected frequency\n",
        "(here we use 95% confidence intervals, so we would expect them to contain\n",
        "the true observation 95% of the time).\n",
        "\n",
        "As the figures below show, the model size (``num_params``) metric is\n",
        "much easier to model than the validation accuracy (``val_acc``) metric.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ax.modelbridge.cross_validation import compute_diagnostics, cross_validate\n",
        "from ax.plot.diagnostic import interact_cross_validation_plotly\n",
        "from ax.utils.notebook.plotting import init_notebook_plotting, render\n",
        "\n",
        "cv = cross_validate(model=gs.model)  # The surrogate model is stored on the GenerationStrategy\n",
        "compute_diagnostics(cv)\n",
        "\n",
        "interact_cross_validation_plotly(cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also make contour plots to better understand how the different\n",
        "objectives depend on two of the input parameters. In the figure below,\n",
        "we show the validation accuracy predicted by the model as a function\n",
        "of the two hidden sizes. The validation accuracy clearly increases\n",
        "as the hidden sizes increase.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from ax.plot.contour import interact_contour_plotly\n",
        "\n",
        "interact_contour_plotly(model=gs.model, metric_name=\"val_acc\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly, we show the number of model parameters as a function of\n",
        "the hidden sizes in the figure below and see that it also increases\n",
        "as a function of the hidden sizes (the dependency on ``hidden_size_1``\n",
        "is much larger).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "interact_contour_plotly(model=gs.model, metric_name=\"num_params\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Acknowledgements\n",
        "\n",
        "We thank the TorchX team (in particular Kiuk Chung and Tristan Rice)\n",
        "for their help with integrating TorchX with Ax.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.15 ('exp_pt')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "21f6fb6ec0df82d9b822214a2115beb7277bde8576d936310f59810ee15b202c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
